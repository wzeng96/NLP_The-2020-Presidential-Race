{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk.data\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.util import bigrams \n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in each candidate data\n",
    "bernie = pd.read_csv(\"./Data/All_Candidates/Bernie_Sanders.csv\")\n",
    "biden = pd.read_csv(\"./Data/All_Candidates/Joe_Biden.csv\")\n",
    "trump = pd.read_csv(\"./Data/All_Candidates/Donald_Trump.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>media</th>\n",
       "      <th>word_count</th>\n",
       "      <th>candidate_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Sign of the Times? The Democratic Primary Ha...</td>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tops in Iowa, Under Attack At Every Turn: [Nat...</td>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gender and War Dominate Debate by 6 Democrats:...</td>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Once Hawking Big-Ticket Ideas, Democrats Refoc...</td>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sanders Gets Endorsement Of Young Climate Grou...</td>\n",
       "      <td>Hide highlightingFull TextTranslateUndo Transl...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  A Sign of the Times? The Democratic Primary Ha...   \n",
       "1  Tops in Iowa, Under Attack At Every Turn: [Nat...   \n",
       "2  Gender and War Dominate Debate by 6 Democrats:...   \n",
       "3  Once Hawking Big-Ticket Ideas, Democrats Refoc...   \n",
       "4  Sanders Gets Endorsement Of Young Climate Grou...   \n",
       "\n",
       "                                                text           media  \\\n",
       "0  Hide highlightingFull TextTranslateUndo Transl...  New York Times   \n",
       "1  Hide highlightingFull TextTranslateUndo Transl...  New York Times   \n",
       "2  Hide highlightingFull TextTranslateUndo Transl...  New York Times   \n",
       "3  Hide highlightingFull TextTranslateUndo Transl...  New York Times   \n",
       "4  Hide highlightingFull TextTranslateUndo Transl...  New York Times   \n",
       "\n",
       "   word_count  candidate_name  \n",
       "0      1122.0  Bernie Sanders  \n",
       "1      1995.0  Bernie Sanders  \n",
       "2      2154.0  Bernie Sanders  \n",
       "3      1892.0  Bernie Sanders  \n",
       "4      1005.0  Bernie Sanders  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text\n",
    "bernie_text = bernie.iloc[:,1]\n",
    "\n",
    "biden_text = biden.iloc[:,1]\n",
    "\n",
    "trump_text = trump.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Hide highlightingFull TextTranslateUndo Transl...\n",
       "1    Hide highlightingFull TextTranslateUndo Transl...\n",
       "2    Hide highlightingFull TextTranslateUndo Transl...\n",
       "3    Hide highlightingFull TextTranslateUndo Transl...\n",
       "4    Hide highlightingFull TextTranslateUndo Transl...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at what is actually in the text\n",
    "bernie_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words I have found in the beggining & end of each text due to scraping\n",
    "remove = ['hide','highlightingfull', 'texttranslateundo', 'translation', 'fromtotranslatetranslation', 'progress', 'missing', 'key',\n",
    " 'loadinganimation', 'full', 'text', 'may', 'take', 'second', 'translate', 'larger', 'document', 'may', 'take', 'longer', 'cancel',\n",
    " 'overlayendturn', 'search', 'term', 'navigationturn', 'navigation', 'jump', 'first', 'hit','article', 'write', 'julie', 'bykowicz',\n",
    " 'credit', 'julie', 'bykowicz', 'word', 'count', 'lessyou', 'requested', 'machine', 'selected', 'content', 'database', 'functionality',\n",
    " 'provided', 'solely', 'convenience', 'way', 'intended', 'replace', 'human', 'show', 'disclaimerneither', 'proquest', 'licensors',\n",
    " 'make', 'representation', 'warranty', 'respect', 'automatically', 'generated', 'available', 'retained', 'system', 'proquest',\n",
    " 'licensors', 'specifically', 'disclaim', 'express', 'implied', 'warranty', 'including', 'without', 'limitation', 'warranty', 'availability',\n",
    " 'accuracy', 'timeliness', 'completeness', 'merchantability', 'fitness', 'particular', 'purpose', 'use', 'subject', 'use', 'restriction',\n",
    " 'contained', 'electronic', 'product', 'license', 'agreement', 'using', 'functionality', 'agree', 'forgo', 'claim', 'proquest', 'licensors',\n",
    " 'use', 'functionality', 'output' 'derived', 'disclaimer','rather','keep', 'waiting','translated', 'paragraph', 'click', 'button', \n",
    " 'want', 'rest', 'allcopyright', 'dow', 'jones', 'company', 'right', 'reserved', 'said', 'ha', 'wa', 'biden', 'trump', 'sander',\n",
    "'would','new', 'two', 'one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include removed words in stop words\n",
    "stopwords = stop_words + remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pre-process data\n",
    "\n",
    "def pre_process_text(text):\n",
    "\n",
    "    # split into tokens\n",
    "    #tokens = treebank_tokenizer.tokenize(text)\n",
    "    \n",
    "    # take out puncutation and numbers\n",
    "    words = [word for word in text if word.isalpha()]\n",
    "    \n",
    "    # convert to lower case\n",
    "    words_l = [word.lower() for word in words]\n",
    "    \n",
    "    # get lemmas\n",
    "    lemmatized_words = [wordnet_lemmatizer.lemmatize(word) for word in words_l]\n",
    "    \n",
    "    # taking out stop_words + remove\n",
    "    output = [w for w in lemmatized_words if w not in stopwords]\n",
    "    \n",
    "    # the later function assumes you are returning a list of terms\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# create list of tokenized articles for each candidate\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "bernie_tokens = []\n",
    "for news in bernie_text[:]:\n",
    "    content = nltk.word_tokenize(news)\n",
    "    bernie_tokens.append(pre_process_text(content))\n",
    "\n",
    "biden_tokens = []\n",
    "for news in biden_text[:]:\n",
    "    content = nltk.word_tokenize(news)\n",
    "    biden_tokens.append(pre_process_text(content))\n",
    "\n",
    "trump_tokens = []\n",
    "for news in trump_text[:]:\n",
    "    content = nltk.word_tokenize(news)\n",
    "    trump_tokens.append(pre_process_text(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out list of token articles\n",
    "#bernie_tokens[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dictionaries for each canididate\n",
    "\n",
    "bernie_tokens_dict = {}\n",
    "biden_tokens_dict = {}\n",
    "trump_tokens_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries with word frequency as value\n",
    "\n",
    "for article in bernie_tokens:\n",
    "    for words in article:\n",
    "        if words in bernie_tokens_dict.keys():\n",
    "            bernie_tokens_dict[words] += 1\n",
    "        else:\n",
    "            bernie_tokens_dict[words] = 1\n",
    "        \n",
    "for article in biden_tokens:\n",
    "    for words in article:\n",
    "        if words in biden_tokens_dict.keys():\n",
    "            biden_tokens_dict[words] += 1\n",
    "        else:\n",
    "            biden_tokens_dict[words] = 1\n",
    "\n",
    "for article in trump_tokens:\n",
    "    for words in article:\n",
    "        if words in trump_tokens_dict.keys():\n",
    "            trump_tokens_dict[words] += 1\n",
    "        else:\n",
    "            trump_tokens_dict[words] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at dictionary\n",
    "#bernie_tokens_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with word and frequency as col\n",
    "# sort them by frequency\n",
    "pd_bernie_tokens=pd.DataFrame(list(bernie_tokens_dict.items()), columns=['bernie_word', 'bernie_freq'])\n",
    "pd_bernie_tokens=pd_bernie_tokens.sort_values(by=\"bernie_freq\" , ascending=False).reset_index(drop=True)\n",
    "\n",
    "pd_biden_tokens=pd.DataFrame(list(biden_tokens_dict.items()), columns=['biden_word', 'biden_freq'])\n",
    "pd_biden_tokens=pd_biden_tokens.sort_values(by=\"biden_freq\" , ascending=False).reset_index(drop=True)\n",
    "\n",
    "pd_trump_tokens=pd.DataFrame(list(trump_tokens_dict.items()), columns=['trump_word', 'trump_freq'])\n",
    "pd_trump_tokens=pd_trump_tokens.sort_values(by=\"trump_freq\" , ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trump_word</th>\n",
       "      <th>trump_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>president</td>\n",
       "      <td>5547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>house</td>\n",
       "      <td>2475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>republican</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>impeachment</td>\n",
       "      <td>1774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>democrat</td>\n",
       "      <td>1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>campaign</td>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>state</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>senate</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>white</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>official</td>\n",
       "      <td>1246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>election</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>democratic</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>trial</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>former</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>people</td>\n",
       "      <td>1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>year</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>also</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>senator</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ukraine</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     trump_word  trump_freq\n",
       "0     president        5547\n",
       "1         house        2475\n",
       "2    republican        2003\n",
       "3   impeachment        1774\n",
       "4      democrat        1715\n",
       "5      campaign        1672\n",
       "6         state        1499\n",
       "7        senate        1477\n",
       "8         white        1407\n",
       "9          time        1333\n",
       "10     official        1246\n",
       "11     election        1203\n",
       "12   democratic        1168\n",
       "13        trial        1145\n",
       "14       former        1143\n",
       "15       people        1121\n",
       "16         year        1077\n",
       "17         also        1071\n",
       "18      senator        1003\n",
       "19      ukraine         961"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_bernie_tokens.head(20)\n",
    "pd_biden_tokens.head(20)\n",
    "pd_trump_tokens.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16029 threads\n",
      "There are 16526 threads\n",
      "There are 16856 threads\n"
     ]
    }
   ],
   "source": [
    "# See how only threads in each candidates\n",
    "print(f'There are {len(pd_bernie_tokens)} threads')\n",
    "print(f'There are {len(pd_biden_tokens)} threads')\n",
    "print(f'There are {len(pd_trump_tokens)} threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Doing Sentiment Analysis for each candidates\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each token as positive, negative or neutral, and generate a score\n",
    "# Bernie first\n",
    "bernie_table = []\n",
    "for i in pd_bernie_tokens['bernie_word']:\n",
    "    bernie_scores = {}\n",
    "    bernie_scores['sia_positive'] = sia.polarity_scores(i)['pos']\n",
    "    bernie_scores['sia_negative'] = sia.polarity_scores(i)['neg']\n",
    "    bernie_scores['sia_neutral'] = sia.polarity_scores(i)['neu']\n",
    "    bernie_scores['sia_compound'] = sia.polarity_scores(i)['compound']\n",
    "    \n",
    "    bernie_table.append(bernie_scores)\n",
    "    \n",
    "#print(sia_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sia_positive  sia_negative  sia_neutral  sia_compound\n",
      "0               1.0           0.0          0.0        0.6486\n",
      "1               1.0           0.0          0.0        0.6369\n",
      "2               1.0           0.0          0.0        0.6369\n",
      "3               1.0           0.0          0.0        0.6369\n",
      "4               1.0           0.0          0.0        0.6369\n",
      "...             ...           ...          ...           ...\n",
      "16024           0.0           1.0          0.0       -0.6908\n",
      "16025           0.0           1.0          0.0       -0.6908\n",
      "16026           0.0           1.0          0.0       -0.6908\n",
      "16027           0.0           1.0          0.0       -0.6908\n",
      "16028           0.0           1.0          0.0       -0.7096\n",
      "\n",
      "[16029 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# See the results\n",
    "bernie_table = pd.DataFrame(bernie_table)\n",
    "bernie_table=bernie_table.sort_values(by='sia_compound' , ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(bernie_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sia_positive      878\n",
       "sia_negative     1139\n",
       "sia_neutral     13999\n",
       "sia_compound      878\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what kinds of sentiment appear more\n",
    "bernie_table[bernie_table > 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sia_positive    15151\n",
       "sia_negative    14890\n",
       "sia_neutral      2030\n",
       "sia_compound    14012\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernie_table[bernie_table == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sia_positive       0\n",
       "sia_negative       0\n",
       "sia_neutral        0\n",
       "sia_compound    1139\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernie_table[bernie_table < 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernie has 7.1% of negative sentiments, 5.5 % of positive sentiments, and 87.4% of neutral sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sia_positive  sia_negative  sia_neutral  sia_compound\n",
      "0               1.0           0.0          0.0        0.6486\n",
      "1               1.0           0.0          0.0        0.6369\n",
      "2               1.0           0.0          0.0        0.6369\n",
      "3               1.0           0.0          0.0        0.6369\n",
      "4               1.0           0.0          0.0        0.6369\n",
      "...             ...           ...          ...           ...\n",
      "16521           0.0           1.0          0.0       -0.6908\n",
      "16522           0.0           1.0          0.0       -0.6908\n",
      "16523           0.0           1.0          0.0       -0.7003\n",
      "16524           0.0           1.0          0.0       -0.7003\n",
      "16525           0.0           1.0          0.0       -0.7096\n",
      "\n",
      "[16526 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Biden\n",
    "biden_table = []\n",
    "for i in pd_biden_tokens['biden_word']:\n",
    "    biden_scores = {}\n",
    "    biden_scores['sia_positive'] = sia.polarity_scores(i)['pos']\n",
    "    biden_scores['sia_negative'] = sia.polarity_scores(i)['neg']\n",
    "    biden_scores['sia_neutral'] = sia.polarity_scores(i)['neu']\n",
    "    biden_scores['sia_compound'] = sia.polarity_scores(i)['compound']\n",
    "    \n",
    "    biden_table.append(biden_scores)\n",
    "    \n",
    "biden_table = pd.DataFrame(biden_table)\n",
    "biden_table=biden_table.sort_values(by='sia_compound' , ascending=False).reset_index(drop=True)\n",
    "print(biden_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sia_positive      895\n",
       "sia_negative     1177\n",
       "sia_neutral     14439\n",
       "sia_compound      895\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_table[biden_table > 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sia_positive    15631\n",
       "sia_negative    15349\n",
       "sia_neutral      2087\n",
       "sia_compound    14454\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_table[biden_table == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sia_positive       0\n",
       "sia_negative       0\n",
       "sia_neutral        0\n",
       "sia_compound    1177\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_table[biden_table < 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biden has 7.1% of negative sentiments, 5.4 % of positive sentiments, and 87.5% of neutral sentiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sia_positive  sia_negative  sia_neutral  sia_compound\n",
      "0               1.0           0.0          0.0        0.6369\n",
      "1               1.0           0.0          0.0        0.6369\n",
      "2               1.0           0.0          0.0        0.6369\n",
      "3               1.0           0.0          0.0        0.6369\n",
      "4               1.0           0.0          0.0        0.6369\n",
      "...             ...           ...          ...           ...\n",
      "16851           0.0           1.0          0.0       -0.6908\n",
      "16852           0.0           1.0          0.0       -0.6908\n",
      "16853           0.0           1.0          0.0       -0.6908\n",
      "16854           0.0           1.0          0.0       -0.7003\n",
      "16855           0.0           1.0          0.0       -0.7096\n",
      "\n",
      "[16856 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Trump\n",
    "trump_table = []\n",
    "for i in pd_trump_tokens['trump_word']:\n",
    "    trump_scores = {}\n",
    "    trump_scores['sia_positive'] = sia.polarity_scores(i)['pos']\n",
    "    trump_scores['sia_negative'] = sia.polarity_scores(i)['neg']\n",
    "    trump_scores['sia_neutral'] = sia.polarity_scores(i)['neu']\n",
    "    trump_scores['sia_compound'] = sia.polarity_scores(i)['compound']\n",
    "    \n",
    "    trump_table.append(trump_scores)\n",
    "    \n",
    "trump_table = pd.DataFrame(trump_table)\n",
    "trump_table=trump_table.sort_values(by='sia_compound' , ascending=False).reset_index(drop=True)\n",
    "print(trump_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sia_positive      931\n",
       "sia_negative     1207\n",
       "sia_neutral     14703\n",
       "sia_compound      931\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_table[trump_table > 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sia_positive    15925\n",
       "sia_negative    15649\n",
       "sia_neutral      2153\n",
       "sia_compound    14718\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_table[trump_table == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sia_positive       0\n",
       "sia_negative       0\n",
       "sia_neutral        0\n",
       "sia_compound    1207\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_table[trump_table < 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trump has 7.16% of negative sentiments, 5.5% of positive sentiments, and 87.3% of neutral sentiments. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
